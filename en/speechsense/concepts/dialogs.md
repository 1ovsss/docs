# {{ speechsense-name }} dialogs

_Dialog_ is a {{ speechsense-name }} object. There are two types of dialogs:

* Audio: Agent's voice conversation with a customer recorded using contact center PBX. As soon as you [upload a conversation's audio](../operations/data/upload-data.md) to {{ speechsense-name }}, it will automatically recognize agent and customer speech.

* Chat: Customer's text chat with an agent or bot. For chats, you need to manually specify message authors before [uploading a chat](../operations/data/upload-chat-text.md) to {{ speechsense-name }}.

There are two dialog directions:

* Outgoing: Initiated by agent.
* Incoming: Initiated by customer.

Analyze dialogs in SpeechSense to evaluate the agents' performance. There are two ways to work with dialogs:

* In the dialog list, [find](../operations/data/manage-dialogs.md) the one you need and view its detailed info.
* [Build a report](../operations/data/manage-reports.md) on dialogs.

## Detailed info about a dialog {#detail}

You [can get](../operations/data/manage-dialogs.md#view-dialog) the following information for each dialog:

* Metadata, e.g., full names of agent and customer, call or message date, dialog language, etc. The metadata list is [defined in the connection](../operations/connection/create.md).
* Conversation audio (only for audio).
* Summary automatically generated by [{{ yagpt-full-name }}](../../yandexgpt/) based on full semantic analysis of the dialog. Technically, a summary provides {{ yagpt-full-name }}'s **Yes**/**No** answers to questions.
* Text transcript of the audio automatically generated by [{{ speechkit-full-name }}](../../speechkit/) (only for audio).
* Text chat messages (only for chats).

You can [search for a text fragment](../operations/data/manage-dialogs.md#find-dialogs) through an audio text transcript or text chat messages in either the customer's or the agent's channel. The search returns exact matches. The found fragments are highlighted in yellow.

The text is automatically tagged with agent and customer [tags](tags.md). These indicate things like whether the agent greeted the customer, whether the customer was in good humor, etc.

## Dialog filtering {#filters}

Filters define the conditions for [searching through dialogs](../operations/data/manage-dialogs.md#filters-dialogs).

There are the following types of filters:

* **Agent**: Agent data.
* **Customer**: Customer data.
* **Bot** (only for chats): Bot data.
* **Speech statistics** (only for audio): Agent and customer speech quality criteria, e.g., speech rate, mutual interruptions, etc.
* **General metadata**: Data about a conversation audio or text chat.
* **Customer tags** and **Agent tags**: Classifiers applied to conversation audio recognition results or text messages. You can learn more about tags [here](tags.md).
* **YandexGPT analysis**: Agent's performance criteria and customer's behavioral characteristics during the dialog, such as whether the agent was polite, whether the customer was on the rude side, etc.

For each filter, you can specify one or more filtering conditions. These can be of four types:

* Date: Select a date range from the calendar.
* Text: Enter a line of text. The search will only return exact matches.
* Number: Specify a range of numbers. You can specify either both range boundaries or just one of them. To find a particular value, specify it for both the top and bottom boundaries. The boundary values are included into the filtering range.
* Boolean: **Yes** or **No**.

You can use multiple filters at the same time to find the dialogs satisfying all the conditions you specified.
